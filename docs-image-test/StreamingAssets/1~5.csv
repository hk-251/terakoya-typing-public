人工知能の定義について、「人間の頭脳活動を極限までシミュレートするシステム」と定義したのは誰ですか？,⻑尾真,松尾豊,西田豊明,中島秀之,長尾真（京都大学名誉教授）です。
人工知能の大まかな分類で、機械学習を取り入れた人工知能は何レベルですか？,レベル1,レベル2,レベル3,レベル4,機械学習を取り入れた人工知能はレベル3です。
ロボットの脳にあたる部分を研究するのは人工知能研究ですが、ロボットの体にあたる部分を研究するのは何研究ですか？,ロボット工学,第五世代コンピュータ,オートメーション,エキスパートシステム,ロボットの体にあたる部分を研究するのはロボット工学です。
世界初の人工知能プログラムはアレン・ニューウェルとハーバード・サイモンによって開発されたもので、何と呼ばれていますか？,ロジック・セオリスト,ディープラーニング,エキスパートシステム,第五世代コンピュータ,世界初の人工知能プログラムは「ロジック・セオリスト」です。
第2次AIブームの時代に注目されたアプローチで、データベースに大量の専門知識をため込んだシステムは何ですか？,エキスパートシステム,機械学習,推論/探索,知識の蓄積,第2次AIブームの時代に注目されたアプローチは「エキスパートシステム」です。
第3次AIブームの時代に登場した技術で、人工知能が自ら知識を獲得する一形態は何ですか？,ディープラーニング,ロジック・セオリスト,エキスパートシステム,第五世代コンピュータ,第3次AIブームの時代に注目された技術は「ディープラーニング」です。
シンギュラリティーに対する懸念が広まった第3次AIブームの時代に、レイ・カールワイルが主に懸念を表明したのは何に関連していますか？,技術的特異点,人間と機械の共存,データセキュリティ,知識の蓄積,レイ・カールワイルはシンギュラリティー（技術的特異点）に対する懸念を表明しました。
現在も重要な研究として継続されているAIの分野は主に何ですか？,機械学習,推論/探索,ロボット工学,知識の蓄積,現在も重要な研究として継続されているAIの分野は「機械学習」です。
人工知能の大まかな分類で、シンプルな制御プログラムに分類されるものは何レベルですか？,レベル1,レベル2,レベル3,レベル4,シンプルな制御プログラムはレベル1に分類されます。
人工知能において、特徴量と呼ばれる変数を自動的に学習する製品は何レベルに分類されますか？,レベル4,レベル1,レベル2,レベル3,特徴量を自動的に学習する製品はレベル4に分類されます。
人工知能の分野で、画像認識や音声認識に該当するものはどれですか？,レベル4,レベル1,レベル2,レベル3,画像認識や音声認識はレベル4の人工知能の分野に該当します。
人工知能の研究分野で「推論」や「探索」の研究が進み、1950年代後半から1960年代にかけてブームになった時期は何次AIブームと呼ばれていますか？,第1次AIブーム,第2次AIブーム,第3次AIブーム,第4次AIブーム,「推論」や「探索」の研究が進み、1950年代後半から1960年代にかけてのブームは第1次AIブームと呼ばれています。
人工知能の分野で、交通情報の予測や検索エンジンに該当するものは何レベルですか？,レベル3,レベル1,レベル2,レベル4,交通情報の予測や検索エンジンはレベル3の人工知能の分野に該当します。
人工知能研究の歴史において、アメリカのペンシルバニア大学で開発された真空管を使った世界初の汎用電子式コンピュータは何と呼ばれていますか？,エニアック(ENIAC),エディソン(Edison),エンジン(Engine),エンツォ(Enzo),アメリカのペンシルバニア大学で開発された真空管を使った世界初の汎用電子式コンピュータは「エニアック(ENIAC)」です。
ダートマス会議の主催者は誰ですか？,ジョン・マッカーシー,マーヴィン・ミンスキー,アレン・ニューウェル,ハーバード・サイモン,⼈⼯知能という言葉が初めて使われたダートマス会議の主催者は「ジョン・マッカーシー」でした。
第1次AIブームは何年代に起こったものですか？,1950年代〜,1960年代〜,1970年代〜,1980年代～,第1次AIブームは「1950年代後半〜1960年代」に起こりました。
第1次AIブームの時代に主に進展した研究は何ですか？,推論/探索の研究,ビッグデータの研究,ロボット工学の研究,ゲーム理論の研究,第1次AIブームの時代に主に進展した研究は「推論/探索の研究」です。
ビッグデータと呼ばれる大量のデータを使用して、人工知能が自ら知識を獲得する形態は何ですか？,ディープラーニング,エキスパートシステム,ロボット工学,シンギュラリティー,ビッグデータを使用して知識を獲得する形態は「ディープラーニング」です。
人工知能とは、計算機による知的な情報処理システムの設計や実現に関する研究分野であり、コンピュータを使って学習・推論・認識・判断など人間と同じ知的な処理能力を持つシステムです。同じシステムであっても、「知性」や「知能」自体の定義がないため、人工知能の具体的な定義は専門家の間でも未だに ___________,存在しない,明確である,一致している,古い,人工知能の「知性」や「知能」の定義には一致していないため、存在しないとされています。
人工知能の大まかな分類では、レベル1からレベル4までがあります。レベル1はシンプルな制御プログラムで、すべての振る舞いがあらかじめ決められています。一方、レベル4はディープラーニングを取り入れた人工知能であり、特徴量による学習が行われます。レベル2とレベル3の違いは、レベル2が探索・推論・知識データを利用して状況に応じてきわめて複雑な振る舞いをするのに対し、レベル3は ___________,適当なデータを使用する,ルールベースで動く,人間のように学習する,あらかじめ定められた振る舞いしかしない,レベル3は非常に多くのサンプルデータから入出力関係を学習します。
人工知能で何か新しいことが実現され、その原理がわかってしまうと、「それは単純な自動化であって知能とは関係ない」と結論付ける人間の心理的な効果を何と呼ぶでしょうか？,AI効果,イノベーションのジレンマ,グループシンキング,テクノロジーショック,AI効果は、新しい技術が実現されると、それが単なる自動化であって知能とは関係ないという人間の心理的な反応を指します。
ダートマス会議は、人工知能という学術研究分野を確立した歴史的な会議でした。この会議で初めてAI（Artificial Intelligence）という用語が用いられたのは何年ですか？,1956年,1946年,1966年,1976年,ダートマス会議で初めてAI（Artificial Intelligence）という用語が用いられたのは1956年です。
エキスパートシステムは、大量の専門知識をデータベースに組み込んだ実用的なシステムです。日本では、政府によって何と名付けられた大型プロジェクトが推進されましたか？,第五世代コンピュータ,第四世代コンピュータ,第六世代コンピュータ,第三世代コンピュータ,エキスパートシステムは第五世代コンピュータと呼ばれる大型プロジェクトが推進された時期に登場しました。
ビッグデータとは何ですか？,大量で複雑なデータの集合,簡単な問題の集合,数学の定理の集合,複雑な問題の集合,ビッグデータは一般的なデータ管理・処理ソフトウェアで扱うことが困難なほど巨大で複雑なデータの集合です。
機械学習において、分析すべきデータや対象物の特徴・特性を定量的に表した数値を何と呼びますか？,特徴量,データセット,アルゴリズム,パラメータ,特徴量は分析すべきデータや対象物の特徴・特性を定量的に表した数値です。
IBMが1989年より開発したチェス専用のスーパーコンピュータは何ですか？,ディープブルー,ディープレッド,ディープグリーン,ディープブラック,ディープブルーはチェス専用のスーパーコンピュータです。1997年にガルリ・カスパロフとの対戦で勝利しました。
第3次AIブームは何年から始まり、どのような技術が主役となりましたか？,2010年,2000年,1990年,1980年,第3次AIブームは2010年から始まり、機械学習・特徴表現学習が主役となりました。
ディープラーニングは、どのようなニューラルネットワークを用いて学習を行うアルゴリズムですか？,ディープニューラルネットワーク,サポートベクターマシン,決定木,ランダムフォレスト,ディープラーニングはディープニューラルネットワークを用いて学習を行うアルゴリズムです。
ダートマス会議で初めてAIという用語が用いられたのは、ジョン・マッカーシーを含む何人の主催者によるものですか？,4人,3人,5人,6人,ダートマス会議でAIという用語が初めて用いられたのはジョン・マッカーシーを含む4人の主催者によるものです。
ディープラーニングを取り入れた人工知能は何を自動的に学習しますか？,特徴量,ルールベース,知識データ,探索・推論,ディープラーニングを取り入れた人工知能は特徴量そのものを自動的に学習します。
探索の方法の一つで、あるノードからつながっている隣のノードをすべて探索することを繰り返す探索方法は（　）です。,幅優先探索,深さ優先探索,プランニング,ヒューリスティックな知識,幅優先探索は、あるノードからつながっている隣のノードをすべて探索することを繰り返す探索方法です。
自分が指すときにスコアが最大(有利)になるように、相手が指すときには最小(不利)になるように戦略を立てる方法は（　）法です。,Mini-Max法,αβ法,モンテカルロ法,ブレイクアウト,Mini-Max法は、自分が指すときにスコアが最大(有利)になるように、相手が指すときには最小(不利)になるように戦略を立てる方法です。
機械学習の一つで、与えられたデータに潜在的に存在するパターンを学ぶことを（　）といいます。,ディープラーニング,コーパス,バックプロパゲーション,オントロジー,ディープラーニングは機械学習の一つで、与えられたデータに潜在的に存在するパターンを学びます。
「is-a」の関係を示す一例として、（　）は動物である、という表現があります。,哺乳類,植物,鳥類,昆虫類,「is-a」の関係は継承関係を表し、例えば「哺乳類は動物である」という表現がそれに該当します。
ある局面まで進んだら、あらかじめ決められた方法でゲームの局面のスコアを評価するという方法を完全に放棄する方法は（　）です。,モンテカルロ法,αβ法,Mini-Max法,ブレイクアウト,モンテカルロ法は、ある局面まで進んだら、あらかじめ決められた方法でゲームの局面のスコアを評価するという方法を完全に放棄する方法です。
深さ優先探索と比べてメモリはあまり必要ではないが、解が必ず最短経路というわけではない探索方法は（　）です。,深さ優先探索,幅優先探索,モンテカルロ法,Mini-Max法,深さ優先探索はメモリ使用量が少ないが、解が最短経路であるとは限らない探索方法です。
シミュレーションなどを通して現状を認識し、問題点を分析した後、目的を達成するための行動順序などを具体化することを（　）といいます。,プランニング,コスト,ヒューリスティックな知識,探索,プランニングは、現状の認識と問題点の分析を通して、目的達成のための具体的な行動順序を立案することを指します。
効率よく探索するための概念で、コストがかかりすぎる探索を省略するときなどに使われるものは（　）です。,コスト,プランニング,ヒューリスティックな知識,探索,コストは、効率的な探索を行うための概念で、コストが高すぎる探索は省略されます。
モンテカルロ法でランダムな手を指しゲームを終局させることを（　）といいます。,ブレイクアウト,ブルートフォース,αβ法,Mini-Max法,ブレイクアウトは、モンテカルロ法でランダムな手を指しゲームを終局させることを指します。
力任せにすべての探索を行う方法、数が多くなると立ちいかなくなる方法は（　）です。,ブルートフォース,ブレイクアウト,αβ法,Mini-Max法,ブルートフォースは、力任せにすべての探索を行う方法で、数が多くなると立ちいかなくなる方法です。
エキスパートシステムなど知識を記述したり共有することは生半可なやり方だと限界がある。そこで、知識を体系化する方法論が必要となり、それが（　）です。,オントロジー,推移律,コーパス,バックプロパゲーション,オントロジーは知識を体系化する方法論で、エキスパートシステムなどで知識を記述したり共有するために必要となります。
「哺乳類 is a 動物」、「人間is a 哺乳類」という二つの関係があるとき、「人間 is a （　）」が成立する。,動物,哺乳類,生物,人間,推移律により、「哺乳類 is a 動物」、「人間 is a 哺乳類」の二つの関係から、「人間 is a 動物」が成立します。
ニューラルネットワークを多層化したものを（　）という。,ディープラーニング,バックプロパゲーション,オートエンコーダ,コーパス,ディープラーニングはニューラルネットワークを多層化したものを指します。
ディープラーニングにて、効率よく学習を行う技術の一つで、ネットワークによる推論結果と正解データを比較し、その誤差を逆伝播させてネットワーク内のパラメータを調整する方法を（　）という。,バックプロパゲーション,ディープラーニング,オートエンコーダ,コーパス,バックプロパゲーションはディープラーニングにて効率よく学習を行う技術の一つで、ネットワークによる推論結果と正解データを比較し、その誤差を逆伝播させてネットワーク内のパラメータを調整します。
機械学習のプログラム自身が学習する仕組みを指す言葉は（　）です。,機械学習,コーパス,オントロジー,ヒューリスティック,機械学習は、機械が自身で学習する仕組みを指す。
人間のような柔軟な知的能力を実現するには、前提知識として世の中の常識を全てプログラムに取り込もうというプロジェクトが（　）です。,CyCプロジェクト,ワトソン,東ロボくん,ILSVRC,CyCプロジェクトは、人間のような柔軟な知的能力を実現するために、前提知識として世の中の常識を全てプログラムに取り込もうとしたプロジェクトです。
ユーザの行動履歴から、ユーザの好みを推測する機械学習を応用したアプリケーションを（　）という。,レコメンデーションエンジン,スパムフィルター,統計的自然言語処理,ディープラーニング,レコメンデーションエンジンは、ユーザの行動履歴から好みを推測するための機械学習を応用したアプリケーションです。
ライトウェイトオントロジーをベースに開発された質問応答プログラムとして、IBMが作ったものは（　）です。,ワトソン,東ロボくん,ILSVRC,CyCプロジェクト,ワトソンは、IBMが開発したライトウェイトオントロジーをベースにした質問応答プログラムです。
神経細胞の動きをコンピュータ上で模倣したものを（　）という。,ニューラルネットワーク,ディープラーニング,バックプロパゲーション,オートエンコーダ,ニューラルネットワークは、神経細胞の動きをコンピュータ上で模倣したものを指します。
ニューラルネットワークによる推論結果と正解データを比較し、その誤差を逆伝播させてネットワーク内のパラメータを調整する方法を（　）という。,バックプロパゲーション,ディープラーニング,オートエンコーダ,コーパス,バックプロパゲーションは、ニューラルネットワークによる推論結果と正解データとの誤差を逆伝播させ、それに基づいてネットワーク内のパラメータを調整する手法を指します。これにより、学習過程での誤差を小さくしていきます。
データをk個のグループに分けることを目的とする手法は？,K-means,ランダムフォレスト,ニューラルネットワーク,サポートベクターマシン(SVM),正解はK-meansです。K-meansはクラスタリング手法で、データを指定されたk個のクラスタに分割します。
機械学習モデルの過学習を防ぐために使われる手法は次のうちどれか？,正則化,ランダムフォレスト,ロジスティック回帰,ニューラルネットワーク,正解は正則化です。正則化はモデルの複雑さを抑制し、過学習を防ぐ役割があります。
機械学習で用いる特徴量の次元を削減し、学習にかかる時間を減らす手法は何か？,主成分分析,K-means,ランダムフォレスト,ニューラルネットワーク,正解は主成分分析です。主成分分析は次元削減の手法で、多数の特徴量から相関のない少数の特徴量へと次元を圧縮します。
教師あり学習の代表的な手法で、回帰問題に使用されるモデルは次のうちどれか？,線形回帰,サポートベクターマシン(SVM),ランダムフォレスト,ニューラルネットワーク,正解は線形回帰です。線形回帰は連続値を予測する回帰問題に使用されるシンプルなモデルです。
ランダムフォレストにおいて、最終的な出力は何を基にしているか？,複数の決定木が出力した結果の平均,ニューラルネットワークの出力,サポートベクターマシンの出力,クラスタリングの結果,正解は複数の決定木が出力した結果の平均です。ランダムフォレストは多数決により最終的な出力を決定します。
機械学習の教師あり学習において、連続値を予測する問題を何と呼ぶか？,回帰問題,分類問題,クラスタリング問題,教師なし学習,正解は回帰問題です。連続値を予測する問題を指します。
教師なし学習で使用される手法で、データの特徴や傾向を知りたい場合に適しているのは次のうちどれか？,クラスタ分析,線形回帰,ランダムフォレスト,ニューラルネットワーク,正解はクラスタ分析です。教師なし学習でデータの傾向や特徴を知りたい場合に使用される手法です。
ランダムフォレストにおいて、複数の決定木の出力結果を組み合わせる際に用いられる方法は？,多数決,平均,中央値,最大値,正解は多数決です。ランダムフォレストでは複数の決定木が出力した結果を組み合わせて最終的な出力を決定します。
主成分分析は何のために使用される手法か？,次元削減,クラスタリング,分類,回帰,正解は次元削減です。主成分分析は特徴量間の相関を分析し、次元削減を行う手法です。
教師あり学習において、出力が離散的な値を予測する問題を何と呼ぶか？,分類問題,回帰問題,クラスタリング問題,教師なし学習,正解は分類問題です。出力が離散的な値を予測する問題を指します。
機械学習でのモデルの評価方法として使用される手法で、未知のデータに対するモデルの性能を評価するためにデータを訓練データとテストデータに分割する手法は何か？,ホールドアウト法,K-分割交差検証,正則化,バギング,正解はホールドアウト法です。未知のデータに対するモデルの性能を評価するためにデータを訓練データとテストデータに分割します。
ランダムフォレストにおいて、データ学習に用いる手法で、一部のデータをランダムに使用する手法は？,ブートストラップサンプリング,正則化,バギング,ブースティング,正解はブートストラップサンプリングです。ランダムフォレストではデータ学習においてブートストラップサンプリングが行われます。
教師あり学習の代表的な手法で、入力に用いる各データ点との距離が最も最大となるような境界線を求める手法は何か？,サポートベクターマシン(SVM),線形回帰,ロジスティック回帰,ニューラルネットワーク,正解はサポートベクターマシン(SVM)です。SVMは入力との距離が最大となるような境界線を求める手法です。
ランダムフォレストにおいて、複数のモデルを作成し学習する手法で、最終的な出力は多数決で決定される手法は何か？,アンサンブル学習,バギング,ブースティング,ランダムサンプリング,正解はアンサンブル学習です。ランダムフォレストはアンサンブル学習の一種で、複数の決定木が出力した結果を多数決で決定します。
教師あり学習の代表的な手法で、シグモイド関数を用いて確率を求め、閾値を設定して分類を行う手法は何か？,ロジスティック回帰,線形回帰,サポートベクターマシン(SVM),ニューラルネットワーク,正解はロジスティック回帰です。ロジスティック回帰
機械学習のニューラルネットワークにおいて、活性化関数として使用され、入力を0から1に写像する関数は何か？,シグモイド関数,ソフトマックス関数,ハイパボリックタンジェント関数,レクティファイドリニアユニット(ReLU),正解はシグモイド関数です。シグモイド関数は入力を0から1に写像するため、主に二値分類の出力層で使用されます。
機械学習の教師あり学習において、正則化の目的で用いられ、一部のパラメータの値をゼロにすることで特徴選択を行う手法は何か？,ラッソ回帰,リッジ回帰,エラスティックネット,K-means,正解はラッソ回帰です。ラッソ回帰は正則化の一種で、一部のパラメータをゼロにすることで特徴選択を行います。
機械学習の教師あり学習において、一部のデータをランダムに使用して複数のモデルを作成し、最終的な出力は多数決で決定する手法は何か？,ランダムフォレスト,ブースティング,バギング,SVM,正解はバギングです。バギングは一部のデータをランダムに使用して複数のモデルを作成し、多数決で最終的な出力を決定します。
機械学習の主成分分析において、多数の特徴量から相関のない少数の特徴量へと次元削減することが主たる目的である手法は何か？,主成分分析,クラスタ分析,回帰分析,ランダムサンプリング,正解は主成分分析です。主成分分析は多数の特徴量から相関のない少数の特徴量へと次元削減する手法です。
機械学習の教師あり学習において、入力と出力の関係を学習する際、予測値と実際の値との誤差をネットワークにフィードバックするアルゴリズムは何か？,誤差逆伝搬法,K-分割交差検証,バッチ正規化,遺伝的アルゴリズム,正解は誤差逆伝搬法です。誤差逆伝搬法は予測値と実際の値との誤差をネットワークにフィードバックして学習を進めるアルゴリズムです。
機械学習の教師なし学習手法で、データをk個のクラスタに分けることを目的とする手法は何か？,K-means,主成分分析,ランダムフォレスト,SVM,正解はK-meansです。K-meansはデータをk個のクラスタに分けるクラスタ分析の手法です。
機械学習の教師なし学習手法で、相関を分析してデータの構造をつかむために使用される手法は何か？,主成分分析,K-means,回帰分析,ランダムサンプリング,正解は主成分分析です。主成分分析は相関を分析してデータの構造をつかむ手法です。
機械学習の評価指標として、混同行列を使用してモデルが推論した結果を評価する手法は何か？,混同行列,ホールドアウト法,K-分割交差検証,正則化,正解は混同行列です。混同行列はモデルが推論した結果を評価するための評価指標の一つです。
機械学習の教師あり学習手法で、一部のデータに重みづけして次のモデルを作成し全体の制度向上を図る手法は何か？,ブースティング,ランダムフォレスト,SVM,誤差逆伝搬法,正解はブースティングです。ブースティングは一部のデータに重みづけして次のモデルを作成し全体の制度向上を図る手法です。
機械学習の代表的な手法で、非常に簡単に見えるが高次元のデータや線形分離できない場合に課題が生じる手法は何か？,サポートベクターマシン(SVM),ランダムフォレスト,ニューラルネットワーク,ラッソ回帰,正解はサポートベクターマシン(SVM)です。SVMは高次元のデータや線形分離できない場合に課題が生じることがあります。
機械学習の教師あり学習手法で、連続値を予測する問題に使用される手法は何か？,線形回帰,ランダムフォレスト,ブースティング,クラスタ分析,正解は線形回帰です。線形回帰は連続値を予測するための手法であり、最もシンプルなモデルの一つです。
機械学習の代表的な手法で、一般にランダムな特徴量を抽出し複数の決定機を作る手法は何か？,ランダムフォレスト,サポートベクターマシン(SVM),クラスタ分析,K-means,正解はランダムフォレストです。ランダムフォレストはランダムな特徴量を抽出し複数の決定機を作り、最終的な出力を多数決で決定する手法です。
機械学習の教師あり学習手法で、出力の値が0.5以上ならば正例、0.5以下ならば負例と判定する手法は何か？,ロジスティック回帰,ニューラルネットワーク,線形回帰,クラスタ分析,正解はロジスティック回帰です。ロジスティック回帰は出力の値が0.5以上ならば正例、0.5以下ならば負例と判定する手法で、主に二値分類に使用されます。
機械学習の教師なし学習手法で、教師あり学習の手法でいうところの教師に相当するものが存在しない手法は何か？,教師なし学習,主成分分析,ランダムサンプリング,ブースティング,正解は教師なし学習です。教師なし学習では出力（正解値）が存在せず、入力データの傾向や特徴を知りたいときに使用されます。
機械学習の教師あり学習手法で、入力に用いる各データ点との距離が最大となるような境界線を求め、パターン分類を行う手法は何か？,サポートベクターマシン(SVM),ニューラルネットワーク,ランダムフォレスト,K-means,正解はサポートベクターマシン(SVM)です。SVMはパターン分類を行う手法で、入力データ点との距離が最大となるような境界線を求めることを目指します。
機械学習の教師あり学習手法で、モデルが推論した結果を評価する手法として一般的なものは何か？,混同行列,主成分分析,ランダムサンプリング,クラスタ分析,正解は混同行列です。混同行列はモデルが推論した結果を評価するために使用される評価指標の一つです。
ディープラーニングにおいて、多層パーセプトロンは⼊⼒層と出⼒層の間に（　）を実装したものである。,隠れ層,出力層,中間層,側面層,多層パーセプトロンは、⼊⼒層と出⼒層の間に隠れ層を実装することで、⾮線形分類が可能となります。
ディープラーニングにおける勾配消失問題は、（　）関数の微分による誤差伝播が関わっています。,シグモイド,ReLU,タンジェント,ソフトマックス,シグモイド関数の微分は0から0.25の間の値しかとらないため、隠れ層をさかのぼるごとに誤差がどんどん小さくなり、勾配消失問題が生じます。
ディープラーニングにおける隠れ層を増やすことによって、（　）に近似する複雑なパターンを扱うことができるとされます。,複雑関数,線形関数,単純関数,指数関数,隠れ層を増やすことで、より複雑な関数を表現し、より複雑なパターンを近似できる可能性があります。
ディープラーニングにおける隠れ層を増やしすぎると、誤差逆伝播法による誤差が届きにくくなる問題を（　）問題と呼ぶ。,勾配消失,収束,過学習,オーバーフィット,隠れ層を増やしすぎると、誤差が逆伝播する際に勾配が急速に小さくなり、届きにくくなる問題を勾配消失問題と呼びます。
ディープラーニングにおける新たなアイデアやアプローチを模索する理由は、隠れ層の増加による（　）問題を解決するためである。,勾配消失,過学習,収束,オーバーフィット,隠れ層の増加に伴う勾配消失問題を解決するために、新たなアイデアやアプローチが必要とされています。
ディープラーニングにおける隠れ層を増やすことで、より複雑な関数を表現し、（　）を近似できるとされる。,複雑なパターン,簡単なパターン,確実なパターン,限定されたパターン,隠れ層を増やすことで、より複雑なパターンを近似できる可能性がある。
ディープラーニングにおける隠れ層を増やすと、活性化関数の微分が掛け合わさるため、隠れ層を遡るにつれ伝播する誤差は（　）していく。,指数関数的に減少,均一に増加,線形に変化,安定になる,活性化関数の微分が掛け合わさるため、隠れ層を遡るにつれ誤差は指数関数的に減少していく。
ディープラーニングにおいて、シグモイド関数の微分によって生じる問題は、（　）問題と呼ばれている。,勾配消失,重み更新,勾配更新,微分困難,シグモイド関数の微分による問題は勾配消失問題として知られています。
ディープラーニングにおける隠れ層の増加は、より（　）な関数を作る可能性があるが、実現に向けて新たなアイデアが必要となる。,複雑な,単純な,限定された,無限大の,隠れ層の増加によってより複雑な関数を作る可能性があるが、そのためには新たなアイデアが必要とされています。
ディープラーニングにおける既存の問題の一つは、隠れ層を増やしすぎると、（　）を行う際に誤差が届きにくくなる問題が発生する。,誤差逆伝播,重み初期化,バイアス調整,学習率調整,隠れ層を増やしすぎると、誤差逆伝播する際に誤差が届きにくくなる問題が発生します。
ディープラーニングの先駆的な手法であるオートエンコーダは、可視層と（　）からなるネットワークである。,隠し層,出力層,圧縮層,入力層,オートエンコーダは可視層と隠れ層から成り立っており、データの特徴を圧縮するために隠れ層を使用します。
オートエンコーダにおける（　）は、入力層に与えるデータと出力層から得られるデータが等しくなるように学習される。,情報圧縮,特徴抽出,情報伝達,誤差最小化,オートエンコーダにおいて、隠れ層の役割は入力データを圧縮し、出力を元のデータに近づけることです。
ディープオートエンコーダを構築するために、オートエンコーダを（　）することが行われる。,重ねる,分割する,消去する,結合する,ディープオートエンコーダは、オートエンコーダを積み重ねることで構築されます。これにより、より多層の特徴抽出が可能になります。
ファインチューニングにおいて、最後の層として（　）が適用され、ネットワーク全体の重み調整を行う。,ロジスティック回帰層,線形回帰層,活性化関数層,softmax層,ファインチューニングにおいて、最後の層としてロジスティック回帰層が適用され、全体の重み調整が行われます。
積層オートエンコーダにおいて、隠れ層の学習を行う際に、（　）から順番に学習を進める。,入力層に近い層,出力層に近い層,中間層,ランダムに選ばれた層,積層オートエンコーダにおいて、隠れ層の学習は入力層に近い層から順に進められます。
深層信念ネットワークでは、オートエンコーダの手法に（　）を適用したものである。,制限付きボルツマンマシン,圧縮付きボルツマンマシン,緩和付きボルツマンマシン,制約付きボルツマンマシン,深層信念ネットワークは、オートエンコーダの手法に制限付きボルツマンマシンを適用したものであり、隠れ層の学習方法が制約付きで行われます。
事前学習なしのアプローチでは、近年、ネットワーク全体を（　）効率よく学習させる手法が確立されている。,同時に,逐次的に,並行して,部分的に,近年のアプローチでは、事前学習なしでネットワーク全体を一度に効率的に学習する手法が確立されています。
勾配消失問題に対処するため、近年は事前学習に代わり（　）を工夫するアプローチが進められている。,活性化関数,学習率,隠れ層の数,最適化手法,勾配消失問題に対処するため、近年は活性化関数の工夫が行われており、より効果的な関数が提案されています。
オートエンコーダは、（　）と（　）から成り立っている。,可視層、出力層,入力層、出力層,可視層、隠れ層,出力層、中間層,オートエンコーダは可視層と隠れ層から成り立っており、入力層と出力層の間に隠れ層が存在します。
ディープラーニングにおけるオートエンコーダは、情報を（　）するために使用される。,圧縮,分類,可視化,生成,ディープラーニングにおけるオートエンコーダは、情報を圧縮するために使用され、隠れ層で情報が圧縮されます。
ディープラーニングの進展には、（　）の法則に基づいて半導体の性能と集積が進化している.,ムーア,ニュートン,アインシュタイン,フーリエ,ディープラーニングの進展には、ハードウェアの進歩が大きくかかわっており、半導体の性能と集積が進化していることがムーアの法則に基づいています.
ディープラーニングにおいて、CPUは（　）を処理する役割を担っている.,一般的なタスク,画像処理,音声処理,文字認識,ディープラーニングにおいて、CPUは一般的なタスクの処理を担当しています。
ディープラーニングにおいて、計算資源が不足することがあり、特にCPUとGPUという2つの演算処理装置が異なる役割を担っている。GPUは（　）に長けている.,画像処理,音声認識,テキスト処理,数値計算,GPUは画像処理に長けており、ディープラーニングにおいてはテンソルによる計算が主要であるため、GPUが適しています。
ディープラーニングにおいて、テンソルによる計算が主になるため、GPUが処理するにはうってつけである。GPUがテンソルによる計算に適していることから、そのようなGPUは（　）と呼ばれる.,GPGPU,汎用GPU,専用GPU,拡張GPU,ディープラーニングにおいてテンソル計算が主要であるため、それに最適化されたGPUはGPGPUと呼ばれています。
ディープラーニング向けのGPUの開発をリードしているのは（　）社である.,NVIDIA,Intel,AMD,Microsoft,ディープラーニング向けのGPUの開発をリードしているのはNVIDIA社であり、多くの機械学習ライブラリはNVIDIA社のGPUを前提としています。
ディープラーニングにおける学習は、モデルがもつパラメータの最適化である。一般的な指標として「バーニーおじさんのルール」といわれる経験則からなる指標では、モデルのパラメータ数の（　）のデータ数が必要とされている.,10倍,5倍,20倍,30倍,一般的な指標として「バーニーおじさんのルール」からなる指標では、モデルのパラメータ数の10倍のデータ数が必要とされています。
ディープラーニングにおいて、データが（　）場合は、データ数そのものを増やすことに注力したり、ディープラーニング以外の手法を考慮することが重要である.,少なすぎる,多すぎる,適切な数,制御できない,ディープラーニングにおいて、データが少なすぎる場合は、データ数そのものを増やすことに注力したり、ディープラーニング以外の手法を考慮することが重要です。
Google社はディープラーニング向けにテンソル計算処理に特化した演算処理装置である（　）を開発している.,TPU,GPU,CPU,APU,Google社はディープラーニング向けにテンソル計算処理に特化した演算処理装置であるTPUを開発しています。
ディープラーニング向けのGPU（GPGPU）の開発をリードしているのは（　）社である.,NVIDIA,Apple,Microsoft,IBM,ディープラーニング向けのGPU（GPGPU）の開発をリードしているのはNVIDIA社であり、多くの機械学習ライブラリはNVIDIA社のGPUを前提としています。
ディープラーニングにおける学習とは、モデルがもつパラメータの最適化である。そのような最適化がどれだけのデータを使うことが（　）かどうかは事前に計算することはできない.,不可能,簡単,困難,複雑,ディープラーニングにおける学習において、使うべき適切なデータ量は問題の複雑さによって異なり、絶対的な指標が存在しないため、事前に計算することは不可能です。